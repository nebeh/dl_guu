{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lj4fby1Y89ll",
    "outputId": "dd842f34-471d-47c6-e7f5-ba39738258fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "j-xP8sFY9L9K"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import skimage as ski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbOsW43h9M_a",
    "outputId": "41d3dee4-90a3-4d87-cb57-486920b1505d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    torch.cuda.empty_cache()\n",
    "    print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "S1lssqRFhhnb"
   },
   "outputs": [],
   "source": [
    "x_data = np.load('/content/gdrive/MyDrive/Exponenta/WindowsShield/Data/data_x.npy')\n",
    "y_data = np.load('/content/gdrive/MyDrive/Exponenta/WindowsShield/Data/data_y.npy')\n",
    "x_data = x_data[1:,:,:,:]\n",
    "y_data = y_data[1:]\n",
    "\n",
    "x_data_tensor = torch.FloatTensor(x_data)\n",
    "y_data_tensor = torch.Tensor(y_data)\n",
    "\n",
    "#Norm\n",
    "x_data_tensor = (x_data_tensor - torch.min(x_data_tensor))/(torch.max(x_data_tensor) - torch.min(x_data_tensor))\n",
    "dataset = TensorDataset(x_data_tensor, y_data_tensor)  #combine to tuple structure\n",
    "\n",
    "#here we form train and test\n",
    "batch_size = 12\n",
    "part = 0.8\n",
    "train_lenght = int(x_data_tensor.shape[0]*part)\n",
    "test_lenght = int(x_data_tensor.shape[0] - train_lenght)\n",
    "\n",
    "train_set, test_set = random_split(dataset, [train_lenght,test_lenght])\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, drop_last=False, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, drop_last=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6hryF8PMER5",
    "outputId": "e2077b6a-6d56-4fbf-9277-9f8c362cad2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of DataSet\t: 981\n",
      "len of trainData\t: 784\n",
      "len of testData\t: 197\n"
     ]
    }
   ],
   "source": [
    "dataset_number = len(dataset)\n",
    "trainData_number = len(train_set)\n",
    "testData_number = len(test_set)\n",
    "print(f'len of DataSet\\t: {dataset_number}')\n",
    "print(f'len of trainData\\t: {trainData_number}')\n",
    "print(f'len of testData\\t: {testData_number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "i76spUtxAMt-"
   },
   "outputs": [],
   "source": [
    "class SelfAttentionBlock(nn.Module):\n",
    "    \"\"\" Self attention Layer\"\"\"\n",
    "    def __init__(self, in_dim):\n",
    "        super(SelfAttentionBlock, self).__init__()\n",
    "        \n",
    "        self.chanel_in = in_dim\n",
    "        #self.activation = activation\n",
    "        \n",
    "        self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim, kernel_size= 1)   #in_dim//8\n",
    "        self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim, kernel_size= 1)\n",
    "        self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim, kernel_size= 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        self.softmax  = nn.Softmax(dim=-1) #\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "            inputs :\n",
    "                x : input feature maps( B X C X W X H)\n",
    "            returns :\n",
    "                out : self attention value + input feature \n",
    "                attention: B X N X N (N is Width*Height)\n",
    "        \"\"\"\n",
    "        m_batchsize, C, width ,height = x.size()\n",
    "        #print('atten: ', m_batchsize,C,width ,height)\n",
    "        proj_query  = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1) # B X CX(N)\n",
    "        proj_key =  self.key_conv(x).view(m_batchsize,-1,width*height) # B X C x (*W*H)\n",
    "        energy =  torch.bmm(proj_query,proj_key) # transpose check\n",
    "        attention = self.softmax(energy) # BX (N) X (N) \n",
    "        proj_value = self.value_conv(x).view(m_batchsize,-1,width*height) # B X C X N\n",
    "\n",
    "        out = torch.bmm(proj_value,attention.permute(0,2,1))\n",
    "        #print('atten2:',out.shape)\n",
    "        out = out.view(m_batchsize,C,width,height)\n",
    "        \n",
    "        out = self.gamma*out + x\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1jNdf-jf9Wj2"
   },
   "outputs": [],
   "source": [
    "class InnerBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(InnerBlock, self).__init__()\n",
    "        \n",
    "        self.InnerOperation = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding='same'),\n",
    "                                   nn.BatchNorm2d(out_channels),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding='same'),\n",
    "                                   nn.BatchNorm2d(out_channels))\n",
    "    def forward(self, x):\n",
    "        out_block = self.InnerOperation(x)\n",
    "        return out_block\n",
    "       \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        self.ResConnect = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding='same'))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out_ResBlock = self.ResConnect(x)\n",
    "        return out_ResBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "z8HP30hc9aoy"
   },
   "outputs": [],
   "source": [
    "class ResNetCustom(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=8, number_class=10):\n",
    "        super(ResNetCustom, self).__init__()\n",
    "        \n",
    "        self.number_class = number_class\n",
    "        \n",
    "        self.Layer_1 = InnerBlock(in_channels, out_channels)\n",
    "        self.Layer_2 = InnerBlock(out_channels, out_channels*2)\n",
    "        self.Layer_3 = InnerBlock(out_channels*2, out_channels*4)\n",
    "        self.Layer_4 = InnerBlock(out_channels*4, out_channels*4)\n",
    "        \n",
    "        self.Skip_1 = ResBlock(in_channels, out_channels)\n",
    "        self.Skip_2 = ResBlock(out_channels, out_channels*2)\n",
    "        self.Skip_3 = ResBlock(out_channels*2, out_channels*4)\n",
    "        self.Skip_4 = ResBlock(out_channels*4, out_channels*4)\n",
    "        \n",
    "        self.Last_Conv = nn.Sequential(nn.Conv2d(out_channels*4, out_channels*1, kernel_size=3, stride=1, padding='same'),\n",
    "                                       SelfAttentionBlock(out_channels*1))\n",
    "  \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out_1 = self.Layer_1(x)\n",
    "        res_1 = self.Skip_1(x)\n",
    "        out_1 = nn.ReLU()(out_1 + res_1)\n",
    "        \n",
    "        out_2 = self.Layer_2(out_1)\n",
    "        res_2 = self.Skip_2(out_1)\n",
    "        out_2 = nn.ReLU()(out_2 + res_2)\n",
    "        \n",
    "        out_3 = self.Layer_3(out_2)\n",
    "        res_3 = self.Skip_3(out_2)\n",
    "        out_3 = nn.ReLU()(out_3 + res_3)\n",
    "        \n",
    "        \n",
    "        out_4 = self.Layer_4(out_3)\n",
    "        res_4 = self.Skip_4(out_3)\n",
    "        out_4 = nn.ReLU()(out_4 + res_4)\n",
    "        out = self.Last_Conv(out_4)\n",
    "        #plt.imshow(out[0][0].cpu().detach().numpy())\n",
    "        #plt.show()\n",
    "        out = nn.MaxPool2d(kernel_size=4, stride=2)(out_4)\n",
    "        \n",
    "        #Fully Connected Leyer: Output has 10 labels\n",
    "        input_layer = torch.reshape(out, (out.shape[0],-1)).to(device)\n",
    "        out = nn.Linear(input_layer.shape[1], self.number_class*5).to(device)(input_layer)  #bias=False\n",
    "        out = nn.ReLU()(out)\n",
    "        out = nn.Linear(self.number_class*5, self.number_class).to(device)(out)\n",
    "        return out \n",
    "\n",
    "#x = ResNetCustom(1,8,10)\n",
    "#print(x(torch.randn(12,1,28,28)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jCvuEMed9cAw"
   },
   "outputs": [],
   "source": [
    "#weights initializing\n",
    "def init_all(model, init_func, *params, **kwargs):\n",
    "    for p in model.parameters():\n",
    "        init_func(p, *params, **kwargs)\n",
    "\n",
    "net = ResNetCustom(in_channels=3, out_channels=32*2, number_class=6).to(device)\n",
    "init_all(net, torch.nn.init.normal_, mean=0.0, std=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73b-S3fSnYjv",
    "outputId": "8a5f1a9c-699c-44cb-f5d4-6bb557b0593a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+------------+\n",
      "|             Modules             | Parameters |\n",
      "+---------------------------------+------------+\n",
      "| Layer_1.InnerOperation.0.weight |    1728    |\n",
      "|  Layer_1.InnerOperation.0.bias  |     64     |\n",
      "| Layer_1.InnerOperation.1.weight |     64     |\n",
      "|  Layer_1.InnerOperation.1.bias  |     64     |\n",
      "| Layer_1.InnerOperation.3.weight |   36864    |\n",
      "|  Layer_1.InnerOperation.3.bias  |     64     |\n",
      "| Layer_1.InnerOperation.4.weight |     64     |\n",
      "|  Layer_1.InnerOperation.4.bias  |     64     |\n",
      "| Layer_2.InnerOperation.0.weight |   73728    |\n",
      "|  Layer_2.InnerOperation.0.bias  |    128     |\n",
      "| Layer_2.InnerOperation.1.weight |    128     |\n",
      "|  Layer_2.InnerOperation.1.bias  |    128     |\n",
      "| Layer_2.InnerOperation.3.weight |   147456   |\n",
      "|  Layer_2.InnerOperation.3.bias  |    128     |\n",
      "| Layer_2.InnerOperation.4.weight |    128     |\n",
      "|  Layer_2.InnerOperation.4.bias  |    128     |\n",
      "| Layer_3.InnerOperation.0.weight |   294912   |\n",
      "|  Layer_3.InnerOperation.0.bias  |    256     |\n",
      "| Layer_3.InnerOperation.1.weight |    256     |\n",
      "|  Layer_3.InnerOperation.1.bias  |    256     |\n",
      "| Layer_3.InnerOperation.3.weight |   589824   |\n",
      "|  Layer_3.InnerOperation.3.bias  |    256     |\n",
      "| Layer_3.InnerOperation.4.weight |    256     |\n",
      "|  Layer_3.InnerOperation.4.bias  |    256     |\n",
      "| Layer_4.InnerOperation.0.weight |   589824   |\n",
      "|  Layer_4.InnerOperation.0.bias  |    256     |\n",
      "| Layer_4.InnerOperation.1.weight |    256     |\n",
      "|  Layer_4.InnerOperation.1.bias  |    256     |\n",
      "| Layer_4.InnerOperation.3.weight |   589824   |\n",
      "|  Layer_4.InnerOperation.3.bias  |    256     |\n",
      "| Layer_4.InnerOperation.4.weight |    256     |\n",
      "|  Layer_4.InnerOperation.4.bias  |    256     |\n",
      "|    Skip_1.ResConnect.0.weight   |    192     |\n",
      "|     Skip_1.ResConnect.0.bias    |     64     |\n",
      "|    Skip_2.ResConnect.0.weight   |    8192    |\n",
      "|     Skip_2.ResConnect.0.bias    |    128     |\n",
      "|    Skip_3.ResConnect.0.weight   |   32768    |\n",
      "|     Skip_3.ResConnect.0.bias    |    256     |\n",
      "|    Skip_4.ResConnect.0.weight   |   65536    |\n",
      "|     Skip_4.ResConnect.0.bias    |    256     |\n",
      "|        Last_Conv.0.weight       |   147456   |\n",
      "|         Last_Conv.0.bias        |     64     |\n",
      "|        Last_Conv.1.gamma        |     1      |\n",
      "|  Last_Conv.1.query_conv.weight  |    4096    |\n",
      "|   Last_Conv.1.query_conv.bias   |     64     |\n",
      "|   Last_Conv.1.key_conv.weight   |    4096    |\n",
      "|    Last_Conv.1.key_conv.bias    |     64     |\n",
      "|  Last_Conv.1.value_conv.weight  |    4096    |\n",
      "|   Last_Conv.1.value_conv.bias   |     64     |\n",
      "+---------------------------------+------------+\n",
      "Total Trainable Params: 2595777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2595777"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameters info\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SEs9lrsT-WX1"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, weight_decay=1e-4, momentum=0)   #lr=0.001, weight_decay=1e-6, Adam\n",
    "#For tuning the lr\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer = optimizer, \n",
    "                                                       mode = 'min', \n",
    "                                                       factor = 0.1, \n",
    "                                                       patience = 10,\n",
    "                                                       threshold = 1e-4,\n",
    "                                                       verbose = 'True')\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9, last_epoch=- 1, verbose=True)\n",
    "Loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "aomWBa6JpJib"
   },
   "outputs": [],
   "source": [
    "def accuracy_train_batch(prediction, target, trainData_number, train_loader, index_b):\n",
    "    global score_positive\n",
    "    #target = target.to(device)\n",
    "    prediction = nn.Softmax(dim=1)(prediction)\n",
    "    index_max = torch.argmax(prediction, dim=1)\n",
    "    for i in range(len(target)):\n",
    "      if (target[i] == index_max[i]):\n",
    "          score_positive +=1\n",
    "    if (index_b == len(train_loader) - 1):\n",
    "      print(f'Epoch Accuracy: {round(score_positive/trainData_number, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rku4CqJs9dlm"
   },
   "outputs": [],
   "source": [
    "#learning network\n",
    "epoche = 100\n",
    "history = []\n",
    "history_epoch = []\n",
    "loss_sum = 0\n",
    "score_positive=0\n",
    "\n",
    "for iteration in range(epoche):\n",
    "    for index_b, (feature, target) in enumerate(train_loader):\n",
    "        target = target.long().to(device)\n",
    "        prediction = net(feature.to(device))\n",
    "\n",
    "        Loss = Loss_function(prediction, target.to(device))\n",
    "        loss_sum += Loss.item()\n",
    "        \n",
    "        #net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        Loss.backward()\n",
    "        optimizer.step()\n",
    "        history.append(Loss.item())\n",
    "        accuracy_train_batch(prediction, target, trainData_number, train_loader, index_b)\n",
    "    scheduler.step(Loss)\n",
    "    print('Current Learning Rate:', scheduler.optimizer.param_groups[0]['lr'])\n",
    "    print(f'Epoche â„–: {iteration}')\n",
    "    print(f'Loss per an epoch: {loss_sum/len(train_loader)}')\n",
    "    history_epoch.append(loss_sum/len(train_loader))\n",
    "    loss_sum=0\n",
    "    score_positive=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jth2GL7P937P"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(history, label=f'Loss = {history[-1]}')\n",
    "ax.legend()\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(9)\n",
    "plt.xlabel('Number Batch')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ayLQjnKH95-S"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(history_epoch, label = f'Average Train Loss: {history[-1]}')\n",
    "ax.legend()\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(9)\n",
    "plt.xlabel('Number Epoch')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbJ-Q0z45xVr"
   },
   "outputs": [],
   "source": [
    "torch.save(net, '/content/gdrive/MyDrive/Exponenta/WindowsShield/Data/ResNetAttention.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XIB_7pS565Rm"
   },
   "outputs": [],
   "source": [
    "#testing\n",
    "score_positive = 0\n",
    "score_negative = 0\n",
    "N_batch = 0\n",
    "for index_b, (feature, target) in enumerate(test_loader):\n",
    "    target = target.long().to(device)\n",
    "    prediction = net(feature.to(device))\n",
    "    prediction = nn.Softmax(dim=1)(prediction)\n",
    "    index_max = torch.argmax(prediction, dim=1)\n",
    "    for i in range(len(target)):\n",
    "      if (target[i] == index_max[i]):\n",
    "          score_positive +=1\n",
    "      else:\n",
    "          score_negative +=1\n",
    "print(f'Test Accuracy: {round(score_positive/testData_number, 3)}')\n",
    "print(f'Test Negative: {round(score_negative/testData_number, 3)}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ResNetCustom.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
